
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_examples\indexes\plot_wls_search.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download__examples_indexes_plot_wls_search.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__examples_indexes_plot_wls_search.py:


Regression - WLS search
----------------------------

.. todo: Explain

.. GENERATED FROM PYTHON SOURCE LINES 8-142



.. image:: /_examples/indexes/images/sphx_glr_plot_wls_search_001.png
    :alt: plot wls search
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))
    c:\users\kelda\desktop\repositories\virtualenvs\venvpy39-datablend\lib\site-packages\statsmodels\regression\linear_model.py:764: RuntimeWarning: divide by zero encountered in log
      llf += 0.5 * np.sum(np.log(self.weights))

    Grid search:
                                0              1              2              3              4              5
    wls-rsquared           0.7084         0.5014         0.4632           0.35         0.3856         0.0857
    wls-rsquare...         0.7055         0.4963         0.4577         0.3434         0.3793         0.0764
    wls-fvalue           238.1111        98.5495        84.5637        52.7798        61.5038         9.1877
    wls-fprob                 0.0            0.0            0.0            0.0            0.0         0.0031
    wls-aic             1142.1399            inf            inf            inf            inf            inf
    wls-bic             1147.3502            inf            inf            inf            inf            inf
    wls-llf               -569.07           -inf           -inf           -inf           -inf           -inf
    wls-mse_model    1247263.0537    178548.3799    138487.1426     67817.7342     68132.4974      7642.3772
    wls-mse_resid       5238.1556      1811.7632      1637.6671      1284.9183      1107.7778       831.8095
    wls-mse_total      17783.8616      3596.9816      3019.9851       1956.967      1784.7952       900.6032
    wls-const_coef       173.1309        258.745       273.2793       315.0898       304.1215       407.9886
    wls-const_std         14.3671        18.3722        18.5426        18.4089        18.5034        15.2131
    wls-const_t...        12.0505        14.0835        14.7379        17.1162        16.4359        26.8183
    wls-const_t...            0.0            0.0            0.0            0.0            0.0            0.0
    wls-const_cil        144.6198        222.286       236.4822       278.5579        267.402       377.7988
    wls-const_ciu         201.642        295.204       310.0765       351.6217       340.8409       438.1785
    wls-x1_coef            3.8689         2.5609         2.3668         1.8229         1.9481         0.6374
    wls-x1_std             0.2507          0.258         0.2574         0.2509         0.2484         0.2103
    wls-x1_tvalue         15.4308         9.9272         9.1959          7.265         7.8424         3.0311
    wls-x1_tprob              0.0            0.0            0.0            0.0            0.0         0.0031
    wls-x1_cil             3.3714         2.0489         1.8561          1.325         1.4551         0.2201
    wls-x1_ciu             4.3665         3.0728         2.8776         2.3209          2.441         1.0547
    wls-s_dw        Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...  Jarque-Ber...
    wls-s_jb_value      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):      Prob(JB):
    wls-s_jb_prob       Cond. No.      Cond. No.      Cond. No.      Cond. No.      Cond. No.      Cond. No.
    wls-s_skew          Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:      Kurtosis:
    wls-s_kurtosis                                                                                          
    wls-s_omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...  Prob(Omnib...
    wls-s_omnib...          Skew:          Skew:          Skew:          Skew:          Skew:          Skew:
    wls-m_dw               0.2633         0.1937         0.1765         0.1321         0.1429         0.0702
    wls-m_jb_value         5.3986         3.7001         5.7639        11.5999        10.3767        16.9273
    wls-m_jb_prob          0.0673         0.1572          0.056          0.003         0.0056         0.0002
    wls-m_skew             0.5659         -0.415        -0.5466        -0.8169        -0.7675        -1.0078
    wls-m_kurtosis         3.1216         3.4461         3.4338         3.3384         3.3665         3.0135
    wls-m_nm_value         5.7253         4.3848          6.358        11.1321        10.2215        14.3714
    wls-m_nm_prob          0.0571         0.1116         0.0416         0.0038          0.006         0.0008
    wls-m_ks_value         0.5116         0.5698         0.5784         0.6066         0.5894         0.7199
    wls-m_ks_prob             0.0            0.0            0.0            0.0            0.0            0.0
    wls-m_shp_v...         0.9715         0.9596          0.951         0.9235         0.9301         0.8775
    wls-m_shp_prob         0.0289         0.0038          0.001            0.0         0.0001            0.0
    wls-m_ad_value          0.891         1.7229         2.0844         3.2418         2.9662          5.057
    wls-m_ad_nnorm          False          False          False          False          False          False
    wls-exog        [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...  [[1.0, 0.0...
    wls-endog       [24.829725...  [24.829725...  [24.829725...  [24.829725...  [24.829725...  [24.829725...
    wls-trend                   c              c              c              c              c              c
    wls-weights     [1.0, 1.0,...  [0.1077705...  [0.0807063...  [0.0344663...  [0.0358726...  [2.8560430...
    wls-W           <statsmode...  <pyamr.met...  <pyamr.met...  <pyamr.met...  <pyamr.met...  <pyamr.met...
    wls-model       <statsmode...  <statsmode...  <statsmode...  <statsmode...  <statsmode...  <statsmode...
    wls-id          WLS(c,Leas...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...  WLS(c,Sig(...






|

.. code-block:: default
   :lineno-start: 8

    # Import class.
    import sys
    import numpy as np
    import pandas as pd
    import matplotlib as mpl
    import matplotlib.pyplot as plt
    import statsmodels.api as sm
    import statsmodels.robust.norms as norms

    # import weights.
    from pyamr.datasets.load import make_timeseries
    from pyamr.core.regression.wls import WLSWrapper
    from pyamr.metrics.weights import SigmoidA

    # ----------------------------
    # set basic configuration
    # ----------------------------
    # Matplotlib options
    mpl.rc('legend', fontsize=6)
    mpl.rc('xtick', labelsize=6)
    mpl.rc('ytick', labelsize=6)

    # Set pandas configuration.
    pd.set_option('display.max_colwidth', 14)
    pd.set_option('display.width', 150)
    pd.set_option('display.precision', 4)

    # ----------------------------
    # create data
    # ----------------------------
    # Create timeseries data
    x, y, f = make_timeseries()

    # -----------------------------
    # Example II
    # -----------------------------
    # This example performs grid search on a number of possible configurations
    # of the WLSWrapper. In particular, it tests the effect of different 
    # objects to compute the weights from the frequencies. It presents both
    # the resulting pandas dataframe and also a figure.

    # Configuration
    # -------------
    # This variable contains the weight functions to test. Note that in 
    # the norms module there are other options such as [norms.HuberT(), 
    # norms.Hampel(), norms.TrimmedMean(), norms.TukeyBiweight(), 
    # norms.AndreWave(), norms.RamsayE()]
    w_func = [
        norms.LeastSquares(),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[10, 90]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[25, 75]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[25, 90]),
        SigmoidA(r=200, g=0.5, offset=0.0, scale=1.0, percentiles=[40, 50])]

    # The grid search parameters.
    grid_params = [
        # {'exog': [x], 'endog': [y], 'trend': ['c']},
        {'exog': [x], 'endog': [y], 'trend': ['c'], 'weights': [f], 'W': w_func}
    ]

    # Grid search
    # ------------
    # Perform grid search.
    summary = WLSWrapper(estimator=sm.WLS) \
        .grid_search(grid_params=grid_params)

    # Show grid results
    # ..todo: It is weird to create an WLSWrapper jut to
    #         be able to use themethod from_list_dataframe.
    #         try to implemented separately.
    print("\nGrid search:")
    print(WLSWrapper().from_list_dataframe(summary).T)

    # Prediction
    # ----------
    # Variables.
    start, end = 10, 150

    # Create figure
    fig, axes = plt.subplots(1, 3, figsize=(10, 5))

    # Plot truth values.
    axes[0].plot(x, y, color='#A6CEE3', alpha=0.5, marker='o',
                 markeredgecolor='k', markeredgewidth=0.5,
                 markersize=5, linewidth=0.75, label='Observed')

    # Plot frequencies
    axes[0].bar(x, f, color='gray', alpha=0.7, label='Frequency')

    # For each of the models in summary
    for i, model in enumerate(summary):

        # Compute predictions.
        preds = model.get_prediction(start=start, end=end)

        # Plot forecasted values.
        axes[0].plot(preds[0, :], preds[1, :],
                     linewidth=1.0,
                     label=model._identifier(short=True))

        # Plot the confidence intervals.
        axes[0].fill_between(preds[0, :],
                             preds[2, :],
                             preds[3, :],
                             alpha=0.1)

        # Plot weights assigned to each observation
        axes[1].plot(model.weights, marker='o', alpha=0.5,
                     markeredgecolor='k', markeredgewidth=0.5,
                     markersize=4, linewidth=0.00,
                     label=model._identifier(short=True))

        # Plot weights converter (W) functions.
        if model.W is not None:
            axes[2].plot(np.linspace(0, 1, 100),
                         model.W.weights(np.linspace(0, 1, 100)),
                         label=model._identifier(short=True))

    # Grid.
    axes[0].grid(linestyle='--', linewidth=0.35, alpha=0.5)
    axes[1].grid(linestyle='--', linewidth=0.35, alpha=0.5)
    axes[2].grid(linestyle='--', linewidth=0.35, alpha=0.5)

    # Legend.
    axes[0].legend(loc=0)
    axes[1].legend(loc=0)
    axes[2].legend(loc=0)

    # Tight layout
    plt.tight_layout()

    # Show.
    plt.show()


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.477 seconds)


.. _sphx_glr_download__examples_indexes_plot_wls_search.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_wls_search.py <plot_wls_search.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_wls_search.ipynb <plot_wls_search.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
